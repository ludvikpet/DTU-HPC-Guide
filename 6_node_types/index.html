
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A beginner-friendly guide for the DTU HPC service">
      
      
      
      
        <link rel="prev" href="../5_python_setup/">
      
      
        <link rel="next" href="../7_debug/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Running HPC Python code - The Hitchhiker's Guide to The HPC</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#node-types-and-their-uses" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="The Hitchhiker&#39;s Guide to The HPC" class="md-header__button md-logo" aria-label="The Hitchhiker's Guide to The HPC" data-md-component="logo">
      
  <img src="../icons/White_RGB.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            The Hitchhiker's Guide to The HPC
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Running HPC Python code
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="The Hitchhiker&#39;s Guide to The HPC" class="md-nav__button md-logo" aria-label="The Hitchhiker's Guide to The HPC" data-md-component="logo">
      
  <img src="../icons/White_RGB.png" alt="logo">

    </a>
    The Hitchhiker's Guide to The HPC
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_access_cluster/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Acessing the cluster
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../2_vscode_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VSCode for remote development
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_github_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Setting up GitHub for collaboration
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../4_project_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Setting up a project on the HPC
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../5_python_setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Python environments on the HPC
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Running HPC Python code
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Running HPC Python code
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#node-types-and-their-uses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Node types and their uses
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-a-python-script-on-an-interactive-gpu-node" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running a python script on an interactive GPU node
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-a-script-on-a-compute-node" class="md-nav__link">
    <span class="md-ellipsis">
      
        Running a script on a compute node
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Running a script on a compute node">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-batch-script" class="md-nav__link">
    <span class="md-ellipsis">
      
        The batch script
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#submitting-and-handling-a-batch-job" class="md-nav__link">
    <span class="md-ellipsis">
      
        Submitting and handling a batch job
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#checking-node-business" class="md-nav__link">
    <span class="md-ellipsis">
      
        Checking node business
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#new-commands-in-this-section" class="md-nav__link">
    <span class="md-ellipsis">
      
        New commands in this section
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../7_debug/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Remote debugging
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../9_file_transfer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transferring files to and from the cluster
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_jupyter/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Jupyter notebooks on the cluster
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_monitoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Monitoring machine learning projects
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_best_practices/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Best-practices for a successful project
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Running HPC Python code</h1>

<p>In order to use the HPC properly, you need to know what nodes are, and how to use them. </p>
<h2 id="node-types-and-their-uses">Node types and their uses<a class="headerlink" href="#node-types-and-their-uses" title="Permanent link">&para;</a></h2>
<p>The DTU cluster has four main types of nodes: <em>login</em>, <em>application</em>, <em>interactive</em> and <em>compute</em> nodes. A node is a single computer in the cluster which provides CPU, memory and potentially GPU for running tasks. Each node has a specific use-case, outlined below: </p>
<table>
<thead>
<tr>
<th style="text-align: left;">Type of node</th>
<th style="text-align: left;">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Login node</td>
<td style="text-align: left;">Handles your connection into the cluster. You always ssh into a login-node, and this is where your VSCode editor session lives</td>
</tr>
<tr>
<td style="text-align: left;">Application node</td>
<td style="text-align: left;">Designed to run software and applications available at databars</td>
</tr>
<tr>
<td style="text-align: left;">Interactive node</td>
<td style="text-align: left;">Allows you to run code directly in a terminal or jupyter notebook</td>
</tr>
<tr>
<td style="text-align: left;">Compute node</td>
<td style="text-align: left;">Only allows running code using batch-jobs. Can either be CPU only or also have a GPU</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Login-nodes</strong>: In all cases, <strong><em>please never run any programs on login nodes</em></strong>. They are to be used only for logging in, and running code will slow the nodes for all other HPC users. </p>
<p><strong>Interactive nodes</strong> are shared between all users. This means that when running code interactively, resources allocated to your program depends on how many other users use the specific interactive node. As a result, your code may run out of memory suddenly, or have slower/faster execution based on the general workload of the interactive node. For this reason, interactive nodes are best used for debugging, running jupyter notebooks and running light code, e.g. visualizations, but not well-suited for heavy tasks such as model training, inference, 3D shape analysis, etc.
Given this specification, you're heavily encouraged to only debug <strong>actively</strong>, as you may be blocking other users from using GPU resources.
There exist interactive nodes which only have a CPU, but some nodes in addition have a GPU.</p>
<p><strong>Compute nodes</strong> All heavy tasks should always be run on compute nodes. 
In addition, if you're profiling code or report run-times of code in your work, the only proper way to measure it is to use compute nodes. The batch job you submit will allocate a specific amount of system resources for your program, and thus runtimes will not be influenced by general system use.
In general, when you can use a compute node then you should, as this is the use which HPC is optimized for. Again, these nodes exist in CPU-only and GPU versions.<br />
Available GPU nodes (compute and interactive) are listed <a href="https://www.hpc.dtu.dk/?page_id=2759">here</a>. The next two subsections show how to use interactive and compute nodes.  </p>
<p><strong>Application nodes</strong> Are designed to run software and applications interactively, and are not relevant for this guide. </p>
</blockquote>
<h2 id="running-a-python-script-on-an-interactive-gpu-node">Running a python script on an interactive GPU node<a class="headerlink" href="#running-a-python-script-on-an-interactive-gpu-node" title="Permanent link">&para;</a></h2>
<p>Assume you have a file <strong><em>file.py</em></strong> on the HPC cluster. Then you can run the file interactively by following these steps: </p>
<ol>
<li>ssh into the cluster</li>
<li>change from a login session to an interactive session by entering a queue name into the terminal and pressing enter</li>
<li>load your python virtual environment</li>
<li>executing the code from the terminal by writing <code>python3 path/to/your/file.py</code></li>
</ol>
<p>Currently available interactive GPU queues are <code>sxm2sh</code>, <code>voltash</code> and <code>a100sh</code>. To start an interactive session, simply enter the node ID, e.g. <code>voltash</code>, in the terminal and press enter. You can log out from a node by running the <code>exit</code> command.</p>
<p>In order to check the current workload of an interactive node, you can start a session on the node and enter <code>nvidia-smi</code>. This will provide terminal output similar to the below: </p>
<div class="codehilite"><pre><span></span><code><span class="nb">+-----------------------------------------------------------------------------------------+</span>
<span class="c">| NVIDIA</span><span class="nb">-</span><span class="c">SMI (some version)  Driver Version: (some version)  CUDA Version: (some version) |</span>
<span class="nb">+-----------------------------------------+------------------------+----------------------+</span>
<span class="c">| GPU  Name                 Persistence</span><span class="nb">-</span><span class="c">M | Bus</span><span class="nb">-</span><span class="c">Id          Disp</span><span class="nt">.</span><span class="c">A | Volatile Uncorr</span><span class="nt">.</span><span class="c"> ECC |</span>
<span class="c">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory</span><span class="nb">-</span><span class="c">Usage | GPU</span><span class="nb">-</span><span class="c">Util  Compute M</span><span class="nt">.</span><span class="c"> |</span>
<span class="c">|                                         |                        |               MIG M</span><span class="nt">.</span><span class="c"> |</span>
<span class="c">|=========================================</span><span class="nb">+</span><span class="c">========================</span><span class="nb">+</span><span class="c">======================|</span>
<span class="c">|   0  Titan X</span><span class="nb">-</span><span class="c">PCIE</span><span class="nb">-</span><span class="c">16GB              On  |  </span><span class="nv">&lt;</span><span class="c">PCI Bus ID 0</span><span class="nv">&gt;</span><span class="c">        |                    0 |</span>
<span class="c">| N/A   46C    P0             47W /  250W |    6468MiB /  16384MiB |      0%      Default |</span>
<span class="c">|                                         |                        |                  N/A |</span>
<span class="nb">+-----------------------------------------+------------------------+----------------------+</span>
<span class="c">|   1  Titan X</span><span class="nb">-</span><span class="c">PCIE</span><span class="nb">-</span><span class="c">16GB              On  |  </span><span class="nv">&lt;</span><span class="c">PCI Bus ID 1</span><span class="nv">&gt;</span><span class="c">        |                    0 |</span>
<span class="c">| N/A   29C    P0             25W /  250W |       4MiB /  16384MiB |      0%      Default |</span>
<span class="c">|                                         |                        |                  N/A |</span>
<span class="nb">+-----------------------------------------+------------------------+----------------------+</span>

<span class="nb">+-----------------------------------------------------------------------------------------+</span>
<span class="c">| Processes:                                                                              |</span>
<span class="c">|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |</span>
<span class="c">|        ID   ID                                                               Usage      |</span>
<span class="c">|=========================================================================================|</span>
<span class="c">|    0   N/A  N/A    </span><span class="nv">&lt;</span><span class="c">process ID</span><span class="nv">&gt;</span><span class="c">      C   </span><span class="nt">...</span><span class="c">some/path                           6152MiB |</span>
<span class="c">|    0   N/A  N/A    </span><span class="nv">&lt;</span><span class="c">process ID</span><span class="nv">&gt;</span><span class="c">      C   </span><span class="nt">...</span><span class="c">some/path                            310MiB |</span>
<span class="nb">+-----------------------------------------------------------------------------------------+</span>
</code></pre></div>

<p>Here, some information from the output has been redacted for security. </p>
<details class="tip">
<summary>output interpretation</summary>
<p>The key outputs of interest to you are mainly the GPU statistics. In this case above, we see the node has two GPUs, each of the type Titan X. Each is connected using PCIE, and has 16GB of memory. 
The GPU with ID 0 is currently running at 47 watts with a temperature of 46 degrees celsius, and is currently using 6468MiB/16384MiB of memory, and thus potentially has resources for your job. Similarly, GPU 1 is unused. 
In this case, if you were to run a script, you should run it on GPU 1, because else you may crash or slow down the large process running on GPU 0. If you already know memory requirements of your script, ensure that there actually is space for it on the GPU, as your job else will crash and you may crash others scripts as well. 
<strong>Please always favor to run on unoccupied GPUs in order to not disturb other users</strong>.  </p>
<p>In order to bind to a specific GPU in an interactive job, you will need to specify the CUDA device in pytorch, e.g.: </p>
<p><code>a = torch.Tensor([1,2,3]).to(torch.device('cuda:1'))</code></p>
<p>Our provided script <em>run-file.sh</em> sets CUDA_VISIBLE_DEVICES such that cuda:0 corresponds to the GPU with the most available free memory, and thus when using this you just need to do:</p>
<p><code>a = torch.Tensor([1,2,3]).to("cuda")</code></p>
<p>In specific cases, the CUDA version may be important for you to download the correct version of pytorch.  </p>
</details>
<h2 id="running-a-script-on-a-compute-node">Running a script on a compute node<a class="headerlink" href="#running-a-script-on-a-compute-node" title="Permanent link">&para;</a></h2>
<p>In order to run a script on a compute node, a <em>batch-script</em> is needed to tell the HPC system how many resources your program will take up. Basically, a batch-script can be understood as you placing an order on the HPC node. When placing the order, you create a <em>batch-job</em> which will be put in a queue. The scheduling system on the HPC then starts your script as soon as it is your turn in the queue, and the required resources are available. </p>
<h4 id="the-batch-script">The batch script<a class="headerlink" href="#the-batch-script" title="Permanent link">&para;</a></h4>
<p>A batch script consists of a combination of batch-job code and bash code, and it should be saved with the file-extension <code>your_batch_filename.sh</code>. An example of a batch-script is provided below: </p>
<div class="codehilite"><pre><span></span><code><span class="ch">#!/bin/sh</span>
<span class="c1">### The following section is the batch-job specific content which places your &quot;order&quot; </span>
<span class="c1">### â€“- specify queue where you want to run your job --</span>
<span class="c1">#BSUB -q gpuv100</span>
<span class="c1">### -- set the job name: this is used for monitoring your job later --</span>
<span class="c1">#BSUB -J testjob</span>
<span class="c1">### -- ask for number of CPU cores (in most cases just leave it as 4) --</span>
<span class="c1">#BSUB -n 4</span>
<span class="c1">### -- Select 1 gpu in exclusive process mode (in most cases leave it as is) --</span>
<span class="c1">#BSUB -gpu &quot;num=1:mode=exclusive_process&quot;</span>
<span class="c1">### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues. Your job is killed if it exceeds.</span>
<span class="c1">#BSUB -W 1:00</span>
<span class="c1">### request 5GB of GPU-memory</span>
<span class="c1">#BSUB -R &quot;rusage[mem=5GB]&quot;</span>
<span class="c1">### set the job to run on a single host machine (don&#39;t change this)</span>
<span class="c1">#BSUB -R &quot;span[hosts=1]&quot;</span>
<span class="c1">### -- set an email address - a mail will be sent with some important statistics about your job and whether it succeeded/failed --</span>
<span class="c1">#BSUB -u your_email_address</span>
<span class="c1">### -- send e-mail notification when job starts -- </span>
<span class="c1">#BSUB -B</span>
<span class="c1">### -- send e-mail notification when job ends with statistics/status --</span>
<span class="c1">#BSUB -N</span>
<span class="c1">### -- Specify the file to which all your terminal output (e.g. print statements) are saved to</span>
<span class="c1">### -- %J will here give it the JobID number which the scheduler assigns when submitting. </span>
<span class="c1">#BSUB -o logs/gpu_%J.out</span>
<span class="c1">### -- Specify the file to which all errors are saved to. Important for debugging if it crashes!</span>
<span class="c1">#BSUB -e gpu_%J.err</span>

<span class="c1">### -- end of batch job options - from here it is just shell code --</span>
module<span class="w"> </span>load<span class="w"> </span>python3/3.10.12
<span class="nb">source</span><span class="w"> </span>path/to/your/environment
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Training model...&quot;</span>
<span class="nv">start</span><span class="o">=</span><span class="k">$(</span>date<span class="w"> </span>+%s<span class="k">)</span><span class="w"> </span><span class="c1">#example timer start</span>
python3<span class="w"> </span>src/train_model.py<span class="w">  </span><span class="c1">#train your model</span>
<span class="nv">stop</span><span class="o">=</span><span class="k">$(</span>date<span class="w"> </span><span class="s1">&#39;+%s&#39;</span><span class="k">)</span><span class="w"> </span><span class="c1">#stop the timer to time how long it took</span>
<span class="nv">elapsed</span><span class="o">=</span><span class="k">$(</span>awk<span class="w"> </span><span class="s2">&quot;BEGIN {print </span><span class="nv">$stop</span><span class="s2"> - </span><span class="nv">$start</span><span class="s2">}&quot;</span><span class="k">)</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;training finished in </span><span class="nv">$elapsed</span><span class="s2"> seconds&quot;</span><span class="w"> </span><span class="c1">#print how long it took</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Running inference&quot;</span>
python3<span class="w"> </span>src/model_inference.py
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Plotting results...&quot;</span>
python3<span class="w"> </span>src/some_result_plots.py
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Finished all scripts. &quot;</span>
</code></pre></div>

<p>The shell code is then executed as soon as it is your turn in the queue. </p>
<p>Here, you may consider the shell code as simply being the same as interacting with the terminal line by line. As a result, you can stack a series of commands as done above which trains a model, followingly runs inference and plots some results while also timing how long model training takes and printing something to the output. </p>
<p>Note that both <code>echo</code> (which is linux for print) and python script terminal outputs will be redirected to the <code>logs/gpu_%J.out</code> file instead of a terminal which you can see as it runs.</p>
<h4 id="submitting-and-handling-a-batch-job">Submitting and handling a batch job<a class="headerlink" href="#submitting-and-handling-a-batch-job" title="Permanent link">&para;</a></h4>
<p>In order to submit the job, enter the following in a terminal: 
<code>bsub &lt; your_batch_filename.sh</code></p>
<p>Your job will then receive a job ID. You can see whether your job is running using <code>bstat</code>. 
You may always kill a job using <code>bkill &lt;jobID number&gt;</code>.</p>
<details class="tip">
<summary>Debugging a batch-script by running as a shell-script</summary>
<p>You may check that your batch script works by changing the permissions of the file to be executable by you:</p>
<p><code>chmod 700 mybatchscript.sh</code></p>
<p>And execute it in an interactive session using:</p>
<p><code>./mybatchscript.sh</code></p>
<p>which will run the shell-script contents but not submit to the queue when invoked in this way. When you're sure it works, press Ctrl and C to cancel execution, and then submit it to the queue using </p>
<p><code>bsub &lt; mybatchscript.sh</code></p>
</details>
<h4 id="checking-node-business">Checking node business<a class="headerlink" href="#checking-node-business" title="Permanent link">&para;</a></h4>
<p>You can check how busy different compute nodes are using the <code>bqueues</code> command. Here, the <code>PEND</code> column shows how many jobs are currently in queue. If you want to check a specific queue, in this case <code>gpua100</code>, you may write: 
<code>bqueues | grep gpua100</code>
to only get the corresponding line.
Available compute nodes with GPUs are listed <a href="https://www.hpc.dtu.dk/?page_id=2759">here</a>. </p>
<h2 id="new-commands-in-this-section">New commands in this section<a class="headerlink" href="#new-commands-in-this-section" title="Permanent link">&para;</a></h2>
<p>Reviewed commands:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Command</th>
<th style="text-align: left;">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>nvidia-smi</code></td>
<td style="text-align: left;">Lists interactive node information over the current active node.</td>
</tr>
<tr>
<td style="text-align: left;"><code>bstat</code></td>
<td style="text-align: left;">Lists information of your current batch jobs.</td>
</tr>
<tr>
<td style="text-align: left;"><code>bqueues</code></td>
<td style="text-align: left;">Lists activity of all compute nodes on cluster.</td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/ludvikpet/DTU-HPC-Tutorial" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.sections", "navigation.expand", "navigation.instant", "toc.integrate"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>